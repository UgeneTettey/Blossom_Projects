{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNCjggC_JCLC"
   },
   "source": [
    "# **Customer Churn Prediction** ¶\n",
    "\n",
    "\n",
    "## **Problem Statement:**\n",
    "\n",
    "Develop a predictive model to identify customers at risk of churning from an investment bank, enabling proactive retention strategies to minimize customer loss and maximize revenue growth.\n",
    "\n",
    "\n",
    "## **About the Dataset**\n",
    "\n",
    "There are 14 columns/features and 10k rows/samples.\n",
    "\n",
    "**RowNumber**—corresponds to the record (row) number and has no effect on the output.\n",
    "\n",
    "**CustomerId**—contains random values and has no effect on customer leaving the bank.\n",
    "\n",
    "**Surname**—the surname of a customer has no impact on their decision to leave the bank.\n",
    "\n",
    "**CreditScore**—can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n",
    "\n",
    "**Geography**—a customer’s location can affect their decision to leave the bank.\n",
    "\n",
    "**Gender**—it’s interesting to explore whether gender plays a role in a customer leaving the bank.\n",
    "\n",
    "**Age**—this is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n",
    "\n",
    "**Tenure**—refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n",
    "\n",
    "**Balance**—also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n",
    "\n",
    "**NumOfProducts**—refers to the number of products that a customer has purchased through the bank.\n",
    "\n",
    "**HasCrCard**—denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n",
    "\n",
    "**IsActiveMember**—active customers are less likely to leave the bank.\n",
    "\n",
    "**EstimatedSalary**—as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n",
    "\n",
    "**Exited**—whether or not the customer left the bank.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsM-UZzFLU6K"
   },
   "source": [
    "## **KNN**\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm is a simple and effective machine learning technique that classifies data points by finding the K most similar instances to a new input and voting for the target class or value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaiYMl810_bx"
   },
   "source": [
    "### **The most commonly used hyperparameters for K-Nearest Neighbors (KNN) algorithm:**\n",
    "\n",
    "n_neighbors: The number of nearest neighbors to consider when making a prediction. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "weights: The weight function used to calculate the distance between samples. Supported weights are 'uniform' (all points have equal weight) and 'distance' (points closer to the query point have higher weight).\n",
    "\n",
    "algorithm: The algorithm used to compute the nearest neighbors. Supported algorithms are 'brute' (exhaustive search), 'kd_tree' (k-d tree search), and 'ball_tree' (ball tree search).\n",
    "\n",
    "leaf_size: The number of samples in each leaf node of the k-d tree or ball tree. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "p: The power parameter for the Minkowski metric. When p=1, it is the Manhattan distance, and when p=2, it is the Euclidean distance.\n",
    "\n",
    "metric: The distance metric used to calculate the distance between samples. Supported metrics are 'minkowski' (Minkowski distance), 'euclidean' (Euclidean distance), 'manhattan' (Manhattan distance), and 'chebyshev' (Chebyshev distance).\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "n_neighbors: 3, 5, 10, 20\n",
    "\n",
    "weights: 'uniform', 'distance'\n",
    "\n",
    "algorithm: 'brute', 'kd_tree', 'ball_tree'\n",
    "\n",
    "leaf_size: 10, 20, 30\n",
    "\n",
    "p: 1, 2\n",
    "\n",
    "metric: 'minkowski', 'euclidean', 'manhattan', 'chebyshev'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VBDLDV06LVR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cM4BNUKTL1d1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-e6wApAqL1lZ",
    "outputId": "05bb1fcd-2604-488d-ad80-5f2d7fac215a"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkO2K9I4L1r1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_csv('/content/drive/My Drive/Churn Project/churn.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "osdVP2q05m1v",
    "outputId": "e2b46dae-c05a-40a4-9e0f-2d180913f458"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vabpuR-z5m4P",
    "outputId": "b3ffbcd9-c08d-4b18-a09e-1c8ae228c05e"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXYD_VtT5m8M",
    "outputId": "21e2784f-65e5-4ec6-b098-e00e46cef88a"
   },
   "outputs": [],
   "source": [
    "# is null?\n",
    "isnull = data.isnull().sum()\n",
    "isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n__3wDIp45E2"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "selected_features = [\n",
    "    'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "    'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "    'IsActiveMember', 'EstimatedSalary'\n",
    "]\n",
    "X = data[selected_features]\n",
    "y = data[['Exited']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibZA46O545HW"
   },
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "X['Geography'] = le.fit_transform(X['Geography'])\n",
    "X['Gender'] = le.fit_transform(X['Gender'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXGEGbzC45Kr"
   },
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']] = scaler.fit_transform(X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j44gSfIV5Dc5"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    X, y, random_state=0, train_size=0.8\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "UUKfmfYe5Di5",
    "outputId": "54aad0c2-3609-4cfd-db1b-c5b1a1c4a248"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = KNeighborsClassifier(n_neighbors=2, metric='euclidean', weights='uniform', algorithm='auto', leaf_size=50, p=2)\n",
    "model.fit(train_X, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2Q1a0T45NM",
    "outputId": "d4c11988-a185-4b6d-86cf-af2ee067f9ec"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "val_prediction = model.predict(val_X)\n",
    "y_pred_proba = model.predict_proba(val_X)[:,1]\n",
    "accuracy = accuracy_score(val_y, val_prediction)\n",
    "print(f'Model accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g_36FlE5cIr",
    "outputId": "64fe832a-f782-4bb3-b1d1-fe0dbebef016"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(val_y, val_prediction))\n",
    "print(classification_report(val_y, val_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfUIhRrS-7zL",
    "outputId": "75577063-7172-4349-ddab-3f4c73cd57d2"
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(val_y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcIiAzYb45Qi",
    "outputId": "211e283e-82e6-4213-f6b3-b866636f506f"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(model, 'churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rfy0exgDYaZ"
   },
   "source": [
    "### **OOP Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUfmT2m8OTMG",
    "outputId": "a01f5484-a8ce-4ed5-d68d-d83286214f8b"
   },
   "outputs": [],
   "source": [
    "class ChurnPrediction:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.train_X = None\n",
    "        self.val_X = None\n",
    "        self.train_y = None\n",
    "        self.val_y = None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        selected_features = [\n",
    "            'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "            'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "            'IsActiveMember', 'EstimatedSalary'\n",
    "        ]\n",
    "        self.X = self.data[selected_features]\n",
    "        self.y = self.data[['Exited']]\n",
    "\n",
    "        # Encoding categorical variables\n",
    "        le = LabelEncoder()\n",
    "        self.X['Geography'] = le.fit_transform(self.X['Geography'])\n",
    "        self.X['Gender'] = le.fit_transform(self.X['Gender'])\n",
    "\n",
    "        # Scaling numerical variables\n",
    "        scaler = MinMaxScaler()\n",
    "        self.X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']] = scaler.fit_transform(self.X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']])\n",
    "\n",
    "    def split_data(self):\n",
    "        self.train_X, self.val_X, self.train_y, self.val_y = train_test_split(\n",
    "            self.X, self.y, random_state=0, train_size=0.8\n",
    "        )\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model = KNeighborsClassifier(n_neighbors=5)\n",
    "        self.model.fit(self.train_X, self.train_y)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        val_prediction = self.model.predict(self.val_X)\n",
    "        accuracy = accuracy_score(self.val_y, val_prediction)\n",
    "        print(f'Model accuracy: {accuracy}')\n",
    "        y_pred_proba = self.model.predict_proba(self.val_X)[:,1]\n",
    "        auc = roc_auc_score(self.val_y, y_pred_proba)\n",
    "        print(f'Model auc score: {auc}')\n",
    "        return accuracy, auc\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        joblib.dump(self.model, model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "\n",
    "# Usage\n",
    "churn = ChurnPrediction('/content/drive/My Drive/Churn Project/churn.csv')\n",
    "churn.load_data()\n",
    "churn.preprocess_data()\n",
    "churn.split_data()\n",
    "churn.train_model()\n",
    "accuracy = churn.evaluate_model()\n",
    "\n",
    "# Save the model\n",
    "churn.save_model('churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ELctLpqDTEB"
   },
   "source": [
    "### **Procedural Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImYu-4GM2TiX",
    "outputId": "f9f9e79a-68af-4133-d0f4-874c8a33ec63"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    selected_features = [\n",
    "        'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "        'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "        'IsActiveMember', 'EstimatedSalary'\n",
    "    ]\n",
    "    X = data[selected_features]\n",
    "    y = data[['Exited']]\n",
    "\n",
    "    # Label encoding\n",
    "    le = LabelEncoder()\n",
    "    X['Geography'] = le.fit_transform(X['Geography'])\n",
    "    X['Gender'] = le.fit_transform(X['Gender'])\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']] = scaler.fit_transform(X[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(\n",
    "        X, y, random_state=0, train_size=0.8\n",
    "    )\n",
    "    return train_X, val_X, train_y, val_y\n",
    "\n",
    "def train_model(train_X, train_y):\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(train_X, train_y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, val_X, val_y):\n",
    "    val_prediction = model.predict(val_X)\n",
    "    accuracy = accuracy_score(val_y, val_prediction)\n",
    "    print(f'Model accuracy: {accuracy}')\n",
    "\n",
    "    auc = roc_auc_score(val_y, val_prediction)\n",
    "    print(f'Model auc score: {auc}')\n",
    "    return accuracy, auc\n",
    "\n",
    "def save_model(model, model_path):\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = joblib.load(model_path)\n",
    "    return model\n",
    "\n",
    "# Usage\n",
    "file_path = '/content/drive/My Drive/Churn Project/churn.csv'\n",
    "data = load_data(file_path)\n",
    "X, y = preprocess_data(data)\n",
    "train_X, val_X, train_y, val_y = split_data(X, y)\n",
    "model = train_model(train_X, train_y)\n",
    "accuracy, auc = evaluate_model(model, val_X, val_y)\n",
    "save_model(model, 'churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mDoUgypvtYz"
   },
   "source": [
    "A Decision Tree Classifier is a type of supervised learning algorithm in machine learning. It works by creating a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. The tree is constructed by recursively partitioning the data into subsets based on the values of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5KPCvs5v1YE"
   },
   "source": [
    "### **The most commonly used hyperparameters for Decision Tree Classifier**:\n",
    "\n",
    "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "\n",
    "max_depth: The maximum depth of the tree. Increasing this number can improve the model's performance, but also increases the risk of overfitting.\n",
    "\n",
    "min_samples_split: The minimum number of samples required to split an internal node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "max_features: The maximum number of features to consider at each split. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "random_state: The random seed used to shuffle the data before splitting it into training and testing sets. Setting this to a fixed value ensures reproducibility of the results.\n",
    "\n",
    "class_weight: The weight assigned to each class during training. This can be useful for imbalanced datasets, where one class has a much larger number of instances than the others.\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "criterion: 'gini', 'entropy'\n",
    "\n",
    "max_depth: 3, 5, 10, None (None means no limit)\n",
    "\n",
    "min_samples_split: 2, 5, 10\n",
    "\n",
    "min_samples_leaf: 1, 5, 10\n",
    "\n",
    "max_features: 'auto', 'sqrt', 'log2', None (None means no limit)\n",
    "\n",
    "random_state: 0, 42, 100\n",
    "\n",
    "class_weight: 'balanced', 'balanced_subsample', None (None means all classes are equal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeEs0rwqDijr"
   },
   "source": [
    "### **OOP Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdv61-0lOTYX",
    "outputId": "c36a66ca-3f0b-4141-cb39-e39c5a4918b2"
   },
   "outputs": [],
   "source": [
    "class ChurnPrediction:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.train_X = None\n",
    "        self.val_X = None\n",
    "        self.train_y = None\n",
    "        self.val_y = None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        selected_features = [\n",
    "            'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "            'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "            'IsActiveMember', 'EstimatedSalary'\n",
    "        ]\n",
    "        self.X = self.data[selected_features]\n",
    "        self.y = self.data[['Exited']]\n",
    "\n",
    "        self.X = pd.get_dummies(self.X, columns = [\"Geography\", \"Gender\"])\n",
    "        #self.X.drop(columns=[\"Geography\", \"Gender\"],axis=1, inplace=True)\n",
    "\n",
    "    def split_data(self):\n",
    "        self.train_X, self.val_X, self.train_y, self.val_y = train_test_split(\n",
    "            self.X, self.y, random_state=0, train_size=0.8\n",
    "        )\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model = DecisionTreeClassifier(random_state=0)\n",
    "        self.model.fit(self.train_X, self.train_y)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        val_prediction = self.model.predict(self.val_X)\n",
    "        accuracy = accuracy_score(self.val_y, val_prediction)\n",
    "        print(f'Model accuracy: {accuracy}')\n",
    "        y_pred_proba = self.model.predict_proba(self.val_X)[:,1]\n",
    "        auc = roc_auc_score(self.val_y, y_pred_proba)\n",
    "        print(f'Model auc score: {auc}')\n",
    "        return accuracy, auc\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        joblib.dump(self.model, model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "\n",
    "# Usage\n",
    "churn = ChurnPrediction('/content/drive/My Drive/Churn Project/churn.csv')\n",
    "churn.load_data()\n",
    "churn.preprocess_data()\n",
    "churn.split_data()\n",
    "churn.train_model()\n",
    "accuracy, auc = churn.evaluate_model()\n",
    "\n",
    "# Save the model\n",
    "churn.save_model('churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfuqBgVZDnNU"
   },
   "source": [
    "### **Procedural Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqvzOJpdOTdF",
    "outputId": "23cae5e1-6596-4d1b-b90c-944b5216c66e"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    selected_features = [\n",
    "        'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "        'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "        'IsActiveMember', 'EstimatedSalary'\n",
    "    ]\n",
    "    X = data[selected_features]\n",
    "    y = data[['Exited']]\n",
    "\n",
    "    X = pd.get_dummies(X, columns = [\"Geography\", \"Gender\"])\n",
    "    #X.drop(columns=[\"Geography\", \"Gender\"], inplace=True)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    return train_test_split(\n",
    "        X, y, random_state=0, train_size=0.8\n",
    "    )\n",
    "\n",
    "def train_model(X, y):\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    val_prediction = model.predict(X)\n",
    "    accuracy = accuracy_score(y, val_prediction)\n",
    "    print(f'Model accuracy: {accuracy}')\n",
    "    y_pred_proba = model.predict_proba(X)[:,1]\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "    print(f'Model auc score: {auc}')\n",
    "    return accuracy, auc\n",
    "\n",
    "def save_model(model, model_path):\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "# Usage\n",
    "file_path = '/content/drive/My Drive/Churn Project/churn.csv'\n",
    "data = load_data(file_path)\n",
    "X, y = preprocess_data(data)\n",
    "train_X, val_X, train_y, val_y = split_data(X, y)\n",
    "model = train_model(train_X, train_y)\n",
    "accuracy, auc = evaluate_model(model, val_X, val_y)\n",
    "save_model(model, 'churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXMALsDkvTZ2"
   },
   "source": [
    "Random Forest is a supervised learning algorithm that combines multiple decision trees to produce a more accurate and stable prediction model. It works by creating a collection of decision trees, where each tree is trained on a random subset of the training data. The final prediction is made by combining the predictions of all the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULCkDZ9bvTl0"
   },
   "source": [
    "### **The most commonly used hyperparameters for Random Forest Classifier:**\n",
    "\n",
    "n_estimators: The number of trees in the forest. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "\n",
    "max_depth: The maximum depth of each tree. Increasing this number can improve the model's performance, but also increases the risk of overfitting.\n",
    "\n",
    "min_samples_split: The minimum number of samples required to split an internal node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. Decreasing this number can lead to overfitting, while increasing it can lead to underfitting.\n",
    "\n",
    "max_features: The maximum number of features to consider at each split. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "max_leaf_nodes: The maximum number of leaf nodes in each tree. Increasing this number can improve the model's performance, but also increases the computation time.\n",
    "\n",
    "min_impurity_decrease: The minimum decrease in impurity required to split an internal node. Increasing this number can lead to underfitting, while decreasing it can lead to overfitting.\n",
    "\n",
    "bootstrap: Whether to use bootstrap sampling to build each tree. If True, each tree is built on a random subset of the training data.\n",
    "\n",
    "oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
    "\n",
    "random_state: The random seed used to shuffle the data before building each tree. Setting this to a fixed value ensures reproducibility of the results.\n",
    "\n",
    "class_weight: The weight assigned to each class during training. This can be useful for imbalanced datasets, where one class has a much larger number of instances than the others.\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "n_estimators: 10, 50, 100, 200\n",
    "\n",
    "criterion: 'gini', 'entropy'\n",
    "\n",
    "max_depth: 3, 5, 10, None (None means no limit)\n",
    "\n",
    "min_samples_split: 2, 5, 10\n",
    "\n",
    "min_samples_leaf: 1, 5, 10\n",
    "\n",
    "max_features: 'auto', 'sqrt', 'log2', None (None means no limit)\n",
    "\n",
    "max_leaf_nodes: 10, 50, 100, None (None means no limit)\n",
    "\n",
    "min_impurity_decrease: 0.0, 0.1, 0.5\n",
    "\n",
    "bootstrap: True, False\n",
    "\n",
    "oob_score: True, False\n",
    "\n",
    "random_state: 0, 42, 100\n",
    "\n",
    "class_weight: 'balanced', 'balanced_subsample', None (None means all classes are equal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1gpy4O8DrbD"
   },
   "source": [
    "### **OOP Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUXntkn2OTgo",
    "outputId": "42f3e2d7-9566-4cbb-fd4f-a062d0098a09"
   },
   "outputs": [],
   "source": [
    "class ChurnPrediction:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.train_X = None\n",
    "        self.val_X = None\n",
    "        self.train_y = None\n",
    "        self.val_y = None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        selected_features = [\n",
    "            'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "            'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "            'IsActiveMember', 'EstimatedSalary'\n",
    "        ]\n",
    "        self.X = self.data[selected_features]\n",
    "        self.y = self.data[['Exited']]\n",
    "\n",
    "        self.X = pd.get_dummies(self.X, columns = [\"Geography\", \"Gender\"])\n",
    "\n",
    "    def split_data(self):\n",
    "        self.train_X, self.val_X, self.train_y, self.val_y = train_test_split(\n",
    "            self.X, self.y, random_state=0, train_size=0.8\n",
    "        )\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model = RandomForestClassifier(random_state=0)\n",
    "        self.model.fit(self.train_X, self.train_y)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        val_prediction = self.model.predict(self.val_X)\n",
    "        accuracy = accuracy_score(self.val_y, val_prediction)\n",
    "        print(f'Model accuracy: {accuracy}')\n",
    "        y_pred_proba = self.model.predict_proba(self.val_X)[:,1]\n",
    "        auc = roc_auc_score(self.val_y, y_pred_proba)\n",
    "        print(f'Model auc score: {auc}')\n",
    "        return accuracy, auc\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        joblib.dump(self.model, model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "\n",
    "# Usage\n",
    "churn = ChurnPrediction('/content/drive/My Drive/Churn Project/churn.csv')\n",
    "churn.load_data()\n",
    "churn.preprocess_data()\n",
    "churn.split_data()\n",
    "churn.train_model()\n",
    "accuracy, auc = churn.evaluate_model()\n",
    "\n",
    "# Save the model\n",
    "churn.save_model('churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ej_uDBuDvFP"
   },
   "source": [
    "### **Procedural Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKolKeyBOTkH",
    "outputId": "2fc95d1f-553e-43c6-cc54-9fd882747c0f"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    selected_features = [\n",
    "        'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "        'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "        'IsActiveMember', 'EstimatedSalary'\n",
    "    ]\n",
    "    X = data[selected_features]\n",
    "    y = data[['Exited']]\n",
    "\n",
    "    X = pd.get_dummies(X, columns = [\"Geography\", \"Gender\"])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    return train_test_split(\n",
    "        X, y, random_state=0, train_size=0.8\n",
    "    )\n",
    "\n",
    "def train_model(X, y):\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    val_prediction = model.predict(X)\n",
    "    accuracy = accuracy_score(y, val_prediction)\n",
    "    print(f'Model accuracy: {accuracy}')\n",
    "    y_pred_proba = model.predict_proba(X)[:,1]\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "    print(f'Model auc score: {auc}')\n",
    "    return accuracy, auc\n",
    "\n",
    "def save_model(model, model_path):\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "# Usage\n",
    "file_path = '/content/drive/My Drive/Churn Project/churn.csv'\n",
    "data = load_data(file_path)\n",
    "X, y = preprocess_data(data)\n",
    "train_X, val_X, train_y, val_y = split_data(X, y)\n",
    "model = train_model(train_X, train_y)\n",
    "accuracy, auc = evaluate_model(model, val_X, val_y)\n",
    "save_model(model, 'churn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt3QA9hZxhuL"
   },
   "source": [
    "Support Vector Machine (SVM) is a supervised learning algorithm that can be used for classification and regression tasks. It works by finding the hyperplane that maximally separates the classes in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ui_ycx2xiJA"
   },
   "source": [
    "### **The most commonly used hyperparameters for Support Vector Machines (SVMs) are:**\n",
    "\n",
    "C: The regularization parameter. It controls the trade-off between the margin and the misclassification error.\n",
    "\n",
    "\n",
    "kernel: The kernel function used to transform the data into a higher dimensional space.\n",
    "\n",
    "\n",
    "gamma: The kernel coefficient. It is used to control the spread of the kernel.\n",
    "degree: The degree of the polynomial kernel.\n",
    "\n",
    "\n",
    "### **Here are some common values for these hyperparameters:**\n",
    "\n",
    "C: 1.0, 10.0, 100.0, 1000.0\n",
    "\n",
    "kernel: 'rbf', 'linear', 'poly', 'sigmoid'\n",
    "\n",
    "gamma: 'scale', 'auto', 0.1, 1.0, 10.0\n",
    "\n",
    "degree: 2, 3, 4, 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzglUFy3DzUH"
   },
   "source": [
    "### **OOP Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzjWcUBTOTnQ",
    "outputId": "d8360bd6-b029-4dc6-c27e-fad12f7e301d"
   },
   "outputs": [],
   "source": [
    "class ChurnPrediction:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.train_X = None\n",
    "        self.val_X = None\n",
    "        self.train_y = None\n",
    "        self.val_y = None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        selected_features = [\n",
    "            'CreditScore', 'Geography', 'Gender', 'Age',\n",
    "            'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "            'IsActiveMember', 'EstimatedSalary'\n",
    "        ]\n",
    "        self.X = self.data[selected_features]\n",
    "        self.y = self.data[['Exited']]\n",
    "\n",
    "        self.X = pd.get_dummies(self.X, columns = [\"Geography\", \"Gender\"])\n",
    "\n",
    "    def split_data(self):\n",
    "        self.train_X, self.val_X, self.train_y, self.val_y = train_test_split(\n",
    "            self.X, self.y, random_state=0, train_size=0.8\n",
    "        )\n",
    "\n",
    "    def train_model(self):\n",
    "        self.model = SVC(probability=True,random_state=0)\n",
    "        self.model.fit(self.train_X, self.train_y)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "      val_prediction = self.model.predict(self.val_X)\n",
    "      accuracy = accuracy_score(self.val_y, val_prediction)\n",
    "      print(f'Model accuracy: {accuracy}')\n",
    "      y_pred_proba = self.model.predict_proba(self.val_X)[:,1]\n",
    "      auc = roc_auc_score(self.val_y, y_pred_proba)\n",
    "      print(f'Model auc score: {auc}')\n",
    "      return accuracy, auc\n",
    "    def save_model(self, model_path):\n",
    "        joblib.dump(self.model, model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.model = joblib.load(model_path)\n",
    "\n",
    "# Usage\n",
    "churn = ChurnPrediction('/content/drive/My Drive/Churn Project/churn.csv')\n",
    "churn.load_data()\n",
    "churn.preprocess_data()\n",
    "churn.split_data()\n",
    "churn.train_model()\n",
    "accuracy, auc = churn.evaluate_model()\n",
    "\n",
    "# Save the model\n",
    "churn.save_model('churn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRVNWzbwOTrH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huPNIDUVOTyK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg4EATyrOT3i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
